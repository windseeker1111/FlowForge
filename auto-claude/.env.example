# Auto Claude Environment Variables
# Copy this file to .env and fill in your values

# Claude Code OAuth Token (REQUIRED)
# Get this by running: claude setup-token
CLAUDE_CODE_OAUTH_TOKEN=your-oauth-token-here

# Model override (OPTIONAL)
# Default: claude-opus-4-5-20251101
# AUTO_BUILD_MODEL=claude-opus-4-5-20251101

# =============================================================================
# DEBUG MODE (OPTIONAL)
# =============================================================================
# Enable debug logging for development and troubleshooting.
# Shows detailed information about runner execution, agent calls, file operations.

# Enable debug mode (default: false)
# DEBUG=true

# Debug log level: 1=basic, 2=detailed, 3=verbose (default: 1)
# DEBUG_LEVEL=1

# Log to file instead of stdout (OPTIONAL)
# DEBUG_LOG_FILE=auto-claude/debug.log

# =============================================================================
# LINEAR INTEGRATION (OPTIONAL)
# =============================================================================
# Enable Linear integration for real-time progress tracking in Linear.
# Get your API key from: https://linear.app/YOUR-TEAM/settings/api

# Linear API Key (OPTIONAL - enables Linear integration)
# LINEAR_API_KEY=lin_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Pre-configured Team ID (OPTIONAL - will auto-detect if not set)
# LINEAR_TEAM_ID=

# Pre-configured Project ID (OPTIONAL - will create project if not set)
# LINEAR_PROJECT_ID=

# =============================================================================
# UI SETTINGS (OPTIONAL)
# =============================================================================
# Enable fancy terminal UI with icons, colors, and interactive menus.
# Set to "false" to use plain text output (useful for CI/CD or log files).

# Enable fancy UI (default: true)
# ENABLE_FANCY_UI=true

# =============================================================================
# GRAPHITI MEMORY INTEGRATION V2 (OPTIONAL)
# =============================================================================
# Enable Graphiti-based persistent memory layer for cross-session context
# retention. Uses FalkorDB as the graph database backend.
#
# V2 supports multiple LLM and embedder providers:
#   - OpenAI (default)
#   - Anthropic (LLM only, use with Voyage for embeddings)
#   - Azure OpenAI
#   - Ollama (local, fully offline)
#
# Prerequisites:
#   1. Start FalkorDB: docker-compose up -d falkordb
#   2. Install Graphiti: pip install graphiti-core[falkordb]
#   3. Configure your chosen provider (see below)

# Enable Graphiti integration (default: false)
# GRAPHITI_ENABLED=true

# =============================================================================
# GRAPHITI: Provider Selection
# =============================================================================
# Choose which providers to use for LLM and embeddings.
# Default is "openai" for both.

# LLM provider: openai | anthropic | azure_openai | ollama
# GRAPHITI_LLM_PROVIDER=openai

# Embedder provider: openai | voyage | azure_openai | ollama
# GRAPHITI_EMBEDDER_PROVIDER=openai

# =============================================================================
# GRAPHITI: OpenAI Provider (Default)
# =============================================================================
# Use OpenAI for both LLM and embeddings. This is the simplest setup.
# Required: OPENAI_API_KEY

# OpenAI API Key
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI Model for LLM (default: gpt-5-mini)
# OPENAI_MODEL=gpt-5-mini

# OpenAI Model for embeddings (default: text-embedding-3-small)
# Available: text-embedding-3-small (1536 dim), text-embedding-3-large (3072 dim)
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# GRAPHITI: Anthropic Provider (LLM only)
# =============================================================================
# Use Anthropic for LLM. Requires separate embedder (use Voyage or OpenAI).
# Example: GRAPHITI_LLM_PROVIDER=anthropic, GRAPHITI_EMBEDDER_PROVIDER=voyage
#
# Required: ANTHROPIC_API_KEY

# Anthropic API Key
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Anthropic Model (default: claude-sonnet-4-5-latest)
# GRAPHITI_ANTHROPIC_MODEL=claude-sonnet-4-5-latest

# =============================================================================
# GRAPHITI: Voyage AI Provider (Embeddings only)
# =============================================================================
# Use Voyage AI for embeddings. Commonly paired with Anthropic LLM.
# Get API key from: https://www.voyageai.com/
#
# Required: VOYAGE_API_KEY

# Voyage AI API Key
# VOYAGE_API_KEY=pa-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Voyage Embedding Model (default: voyage-3)
# Available: voyage-3 (1024 dim), voyage-3-lite (512 dim)
# VOYAGE_EMBEDDING_MODEL=voyage-3

# =============================================================================
# GRAPHITI: Azure OpenAI Provider
# =============================================================================
# Use Azure OpenAI for both LLM and embeddings.
# Requires Azure OpenAI deployment with appropriate models.
#
# Required: AZURE_OPENAI_API_KEY, AZURE_OPENAI_BASE_URL

# Azure OpenAI API Key
# AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Azure OpenAI Base URL (your Azure endpoint)
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment

# Azure OpenAI Deployment Names
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-5
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# =============================================================================
# GRAPHITI: Ollama Provider (Local/Offline)
# =============================================================================
# Use Ollama for fully offline operation. No API keys required.
# Requires Ollama running locally with appropriate models pulled.
#
# Prerequisites:
#   1. Install Ollama: https://ollama.ai/
#   2. Pull models: ollama pull deepseek-r1:7b && ollama pull nomic-embed-text
#   3. Start Ollama server (usually auto-starts)
#
# Required: OLLAMA_LLM_MODEL, OLLAMA_EMBEDDING_MODEL, OLLAMA_EMBEDDING_DIM

# Ollama Server URL (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Ollama LLM Model
# Popular choices: deepseek-r1:7b, llama3.2:3b, mistral:7b, phi3:medium
# OLLAMA_LLM_MODEL=deepseek-r1:7b

# Ollama Embedding Model
# Popular choices: nomic-embed-text (768 dim), mxbai-embed-large (1024 dim)
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama Embedding Dimension (REQUIRED for Ollama embeddings)
# Must match your embedding model's output dimension
# Common values: nomic-embed-text=768, mxbai-embed-large=1024, all-minilm=384
# OLLAMA_EMBEDDING_DIM=768

# =============================================================================
# GRAPHITI MCP SERVER (OPTIONAL - Agent-accessible knowledge graph)
# =============================================================================
# Enable Graphiti MCP server for direct agent access to knowledge graph.
# This is SEPARATE from GRAPHITI_ENABLED (Python library integration).
#
# With MCP server enabled, Claude agents can directly:
#   - Search for relevant context (search_nodes, search_facts)
#   - Add discoveries to the graph (add_episode)
#   - Retrieve recent sessions (get_episodes)
#
# Prerequisites:
#   1. Run the Graphiti MCP server via Docker:
#      docker run -d -p 8000:8000 \
#        -e OPENAI_API_KEY=$OPENAI_API_KEY \
#        -e FALKORDB_URI=redis://host.docker.internal:6380 \
#        falkordb/graphiti-knowledge-graph-mcp
#
# See: https://docs.falkordb.com/agentic-memory/graphiti-mcp-server.html

# Graphiti MCP Server URL (setting this enables MCP integration)
# GRAPHITI_MCP_URL=http://localhost:8000/mcp/

# =============================================================================
# GRAPHITI: FalkorDB Connection Settings
# =============================================================================
# Configure the FalkorDB graph database connection.
# Start FalkorDB: docker run -p 6380:6379 falkordb/falkordb:latest

# FalkorDB Host (default: localhost)
# GRAPHITI_FALKORDB_HOST=localhost

# FalkorDB Port (default: 6380)
# GRAPHITI_FALKORDB_PORT=6380

# FalkorDB Password (default: empty)
# GRAPHITI_FALKORDB_PASSWORD=

# Graph Database Name (default: auto_build_memory)
# GRAPHITI_DATABASE=auto_build_memory

# =============================================================================
# GRAPHITI: Miscellaneous Settings
# =============================================================================

# Disable Graphiti telemetry (default: true)
# GRAPHITI_TELEMETRY_ENABLED=false

# =============================================================================
# GRAPHITI: Example Configurations
# =============================================================================
#
# --- Example 1: OpenAI (simplest) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=openai
# GRAPHITI_EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=sk-xxxxxxxx
#
# --- Example 2: Anthropic + Voyage (high quality) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=anthropic
# GRAPHITI_EMBEDDER_PROVIDER=voyage
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxx
# VOYAGE_API_KEY=pa-xxxxxxxx
#
# --- Example 3: Ollama (fully offline) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=ollama
# GRAPHITI_EMBEDDER_PROVIDER=ollama
# OLLAMA_LLM_MODEL=deepseek-r1:7b
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_EMBEDDING_DIM=768
#
# --- Example 4: Azure OpenAI (enterprise) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=azure_openai
# GRAPHITI_EMBEDDER_PROVIDER=azure_openai
# AZURE_OPENAI_API_KEY=xxxxxxxx
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/...
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-5
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
