# Auto Claude Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# AUTHENTICATION (REQUIRED)
# =============================================================================
# Auto Claude uses Claude Code OAuth authentication.
# Direct API keys (ANTHROPIC_API_KEY) are NOT supported to prevent silent billing.
#
# Option 1: Run `claude setup-token` to save token to system keychain (recommended)
#           (macOS: Keychain, Windows: Credential Manager, Linux: secret-service)
# Option 2: Set the token explicitly:
# CLAUDE_CODE_OAUTH_TOKEN=your-oauth-token-here
#
# For enterprise/proxy setups (CCR):
# ANTHROPIC_AUTH_TOKEN=sk-zcf-x-ccr

# =============================================================================
# CUSTOM API ENDPOINT (OPTIONAL)
# =============================================================================
# Override the default Anthropic API endpoint. Useful for:
#   - Local proxies (ccr, litellm)
#   - API gateways
#   - Self-hosted Claude instances
#
# ANTHROPIC_BASE_URL=http://127.0.0.1:3456
#
# Related settings (usually set together with ANTHROPIC_BASE_URL):
# NO_PROXY=127.0.0.1
# DISABLE_TELEMETRY=true
# DISABLE_COST_WARNINGS=true
# API_TIMEOUT_MS=600000

# Model override (OPTIONAL)
# Default: claude-opus-4-5-20251101
# AUTO_BUILD_MODEL=claude-opus-4-5-20251101


# =============================================================================
# GIT/WORKTREE SETTINGS (OPTIONAL)
# =============================================================================
# Configure how Auto Claude handles git worktrees for isolated builds.

# Default base branch for worktree creation (OPTIONAL)
# If not set, Auto Claude will auto-detect main/master, or fall back to current branch.
# Common values: main, master, develop
# DEFAULT_BRANCH=main

# =============================================================================
# DEBUG MODE (OPTIONAL)
# =============================================================================
# Enable debug logging for development and troubleshooting.
# Shows detailed information about runner execution, agent calls, file operations.

# Enable debug mode (default: false)
# DEBUG=true

# Debug log level: 1=basic, 2=detailed, 3=verbose (default: 1)
# DEBUG_LEVEL=1

# Log to file instead of stdout (OPTIONAL)
# DEBUG_LOG_FILE=auto-claude/debug.log

# =============================================================================
# LINEAR INTEGRATION (OPTIONAL)
# =============================================================================
# Enable Linear integration for real-time progress tracking in Linear.
# Get your API key from: https://linear.app/YOUR-TEAM/settings/api

# Linear API Key (OPTIONAL - enables Linear integration)
# LINEAR_API_KEY=lin_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Pre-configured Team ID (OPTIONAL - will auto-detect if not set)
# LINEAR_TEAM_ID=

# Pre-configured Project ID (OPTIONAL - will create project if not set)
# LINEAR_PROJECT_ID=

# =============================================================================
# GITLAB INTEGRATION (OPTIONAL)
# =============================================================================
# Enable GitLab integration for issue tracking and merge requests.
# Supports both GitLab.com and self-hosted GitLab instances.
#
# Authentication Options (choose one):
#
#   Option 1: glab CLI OAuth (Recommended)
#   Install glab CLI: https://gitlab.com/gitlab-org/cli#installation
#   Then run: glab auth login
#   This opens your browser for OAuth authentication. Once complete,
#   Auto Claude will automatically use your glab credentials (no env vars needed).
#   For self-hosted: glab auth login --hostname gitlab.example.com
#
#   Option 2: Personal Access Token
#   Set GITLAB_TOKEN below. Token auth is used if set, otherwise falls back to glab CLI.

# GitLab Instance URL (OPTIONAL - defaults to gitlab.com)
# For self-hosted: GITLAB_INSTANCE_URL=https://gitlab.example.com
# GITLAB_INSTANCE_URL=https://gitlab.com

# GitLab Personal Access Token (OPTIONAL - only needed if not using glab CLI)
# Required scope: api (covers issues, merge requests, releases, project info)
# Optional scope: write_repository (only if creating new GitLab projects from local repos)
# Get from: https://gitlab.com/-/user_settings/personal_access_tokens
# GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx

# GitLab Project (OPTIONAL - format: group/project or numeric ID)
# If not set, will auto-detect from git remote
# GITLAB_PROJECT=mygroup/myproject

# =============================================================================
# UI SETTINGS (OPTIONAL)
# =============================================================================
# Enable fancy terminal UI with icons, colors, and interactive menus.
# Set to "false" to use plain text output (useful for CI/CD or log files).

# Enable fancy UI (default: true)
# ENABLE_FANCY_UI=true

# =============================================================================
# ELECTRON MCP SERVER (OPTIONAL)
# =============================================================================
# Enable Electron MCP server for AI agents to interact with and validate
# Electron desktop applications. This allows QA agents to capture screenshots,
# inspect windows, and validate Electron apps during the review process.
#
# The electron-mcp-server connects via Chrome DevTools Protocol to an Electron
# app running with remote debugging enabled.
#
# Prerequisites:
#   1. Start your Electron app with remote debugging:
#      ./YourElectronApp --remote-debugging-port=9222
#
#   2. For auto-claude-ui specifically (use the MCP-enabled scripts):
#      cd auto-claude-ui
#      pnpm run dev:mcp     # Development mode with MCP debugging
#      # OR for production build:
#      pnpm run start:mcp   # Production mode with MCP debugging
#
# Note: Only QA agents (qa_reviewer, qa_fixer) receive Electron MCP tools.
# Coder and Planner agents do NOT have access to these tools to minimize
# context token usage and keep agents focused on their roles.
#
# See: https://github.com/anthropics/anthropic-quickstarts/tree/main/mcp-electron-demo

# Enable Electron MCP integration (default: false)
# ELECTRON_MCP_ENABLED=true

# Chrome DevTools debugging port for Electron connection (default: 9222)
# ELECTRON_DEBUG_PORT=9222

# =============================================================================
# GRAPHITI MEMORY INTEGRATION (REQUIRED)
# =============================================================================
# Graphiti-based persistent memory layer for cross-session context
# retention. Uses LadybugDB as the embedded graph database.
#
# REQUIREMENTS:
#   - Python 3.12 or higher
#   - Install: pip install real_ladybug graphiti-core
#
# Supports multiple LLM and embedder providers:
#   - OpenAI (default)
#   - Anthropic (LLM only, use with Voyage for embeddings)
#   - Azure OpenAI
#   - Ollama (local, fully offline)
#   - Google AI (Gemini)

# Graphiti is enabled by default. Set to false to disable memory features.
GRAPHITI_ENABLED=true

# =============================================================================
# GRAPHITI: Database Settings
# =============================================================================
# LadybugDB stores data in a local directory (no Docker required).

# Database name (default: auto_claude_memory)
# GRAPHITI_DATABASE=auto_claude_memory

# Database storage path (default: ~/.auto-claude/memories)
# GRAPHITI_DB_PATH=~/.auto-claude/memories

# =============================================================================
# GRAPHITI: Provider Selection
# =============================================================================
# Choose which providers to use for LLM and embeddings.
# Default is "openai" for both.

# LLM provider: openai | anthropic | azure_openai | ollama | google | openrouter
# GRAPHITI_LLM_PROVIDER=openai

# Embedder provider: openai | voyage | azure_openai | ollama | google | openrouter
# GRAPHITI_EMBEDDER_PROVIDER=openai

# =============================================================================
# GRAPHITI: OpenAI Provider (Default)
# =============================================================================
# Use OpenAI for both LLM and embeddings. This is the simplest setup.
# Required: OPENAI_API_KEY

# OpenAI API Key
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI Model for LLM (default: gpt-4o-mini)
# OPENAI_MODEL=gpt-4o-mini

# OpenAI Model for embeddings (default: text-embedding-3-small)
# Available: text-embedding-3-small (1536 dim), text-embedding-3-large (3072 dim)
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# GRAPHITI: Anthropic Provider (LLM only)
# =============================================================================
# Use Anthropic for LLM. Requires separate embedder (use Voyage or OpenAI).
# Example: GRAPHITI_LLM_PROVIDER=anthropic, GRAPHITI_EMBEDDER_PROVIDER=voyage
#
# Required: ANTHROPIC_API_KEY

# Anthropic API Key
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Anthropic Model (default: claude-sonnet-4-5-latest)
# GRAPHITI_ANTHROPIC_MODEL=claude-sonnet-4-5-latest

# =============================================================================
# GRAPHITI: Voyage AI Provider (Embeddings only)
# =============================================================================
# Use Voyage AI for embeddings. Commonly paired with Anthropic LLM.
# Get API key from: https://www.voyageai.com/
#
# Required: VOYAGE_API_KEY

# Voyage AI API Key
# VOYAGE_API_KEY=pa-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Voyage Embedding Model (default: voyage-3)
# Available: voyage-3 (1024 dim), voyage-3-lite (512 dim)
# VOYAGE_EMBEDDING_MODEL=voyage-3

# =============================================================================
# GRAPHITI: Google AI Provider
# =============================================================================
# Use Google AI (Gemini) for both LLM and embeddings.
# Get API key from: https://aistudio.google.com/apikey
#
# Required: GOOGLE_API_KEY

# Google AI API Key
# GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google LLM Model (default: gemini-2.0-flash)
# GOOGLE_LLM_MODEL=gemini-2.0-flash

# Google Embedding Model (default: text-embedding-004)
# GOOGLE_EMBEDDING_MODEL=text-embedding-004

# =============================================================================
# GRAPHITI: OpenRouter Provider (Multi-provider aggregator)
# =============================================================================
# Use OpenRouter to access multiple LLM providers through a single API.
# OpenRouter provides access to Anthropic, OpenAI, Google, and many other models.
# Get API key from: https://openrouter.ai/keys
#
# Required: OPENROUTER_API_KEY

# OpenRouter API Key
# OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenRouter Base URL (default: https://openrouter.ai/api/v1)
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# OpenRouter LLM Model (default: anthropic/claude-sonnet-4)
# Popular choices: anthropic/claude-sonnet-4, openai/gpt-4o, google/gemini-2.0-flash
# OPENROUTER_LLM_MODEL=anthropic/claude-sonnet-4

# OpenRouter Embedding Model (default: openai/text-embedding-3-small)
# OPENROUTER_EMBEDDING_MODEL=openai/text-embedding-3-small

# =============================================================================
# GRAPHITI: Azure OpenAI Provider
# =============================================================================
# Use Azure OpenAI for both LLM and embeddings.
# Requires Azure OpenAI deployment with appropriate models.
#
# Required: AZURE_OPENAI_API_KEY, AZURE_OPENAI_BASE_URL

# Azure OpenAI API Key
# AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Azure OpenAI Base URL (your Azure endpoint)
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment

# Azure OpenAI Deployment Names
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# =============================================================================
# GRAPHITI: Ollama Provider (Local/Offline)
# =============================================================================
# Use Ollama for fully offline operation. No API keys required.
# Requires Ollama running locally with appropriate models pulled.
#
# Prerequisites:
#   1. Install Ollama: https://ollama.ai/
#   2. Pull models: ollama pull deepseek-r1:7b && ollama pull nomic-embed-text
#   3. Start Ollama server (usually auto-starts)
#
# Required: OLLAMA_LLM_MODEL, OLLAMA_EMBEDDING_MODEL, OLLAMA_EMBEDDING_DIM

# Ollama Server URL (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Ollama LLM Model
# Popular choices: deepseek-r1:7b, llama3.2:3b, mistral:7b, phi3:medium
# OLLAMA_LLM_MODEL=deepseek-r1:7b

# Ollama Embedding Model
# Popular choices: nomic-embed-text (768 dim), mxbai-embed-large (1024 dim)
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama Embedding Dimension (REQUIRED for Ollama embeddings)
# Must match your embedding model's output dimension
# Common values: nomic-embed-text=768, mxbai-embed-large=1024, all-minilm=384
# OLLAMA_EMBEDDING_DIM=768

# =============================================================================
# GRAPHITI: Example Configurations
# =============================================================================
#
# --- Example 1: OpenAI (simplest) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=openai
# GRAPHITI_EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=sk-xxxxxxxx
#
# --- Example 2: Anthropic + Voyage (high quality) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=anthropic
# GRAPHITI_EMBEDDER_PROVIDER=voyage
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxx
# VOYAGE_API_KEY=pa-xxxxxxxx
#
# --- Example 3: Ollama (fully offline) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=ollama
# GRAPHITI_EMBEDDER_PROVIDER=ollama
# OLLAMA_LLM_MODEL=deepseek-r1:7b
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_EMBEDDING_DIM=768
#
# --- Example 4: Azure OpenAI (enterprise) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=azure_openai
# GRAPHITI_EMBEDDER_PROVIDER=azure_openai
# AZURE_OPENAI_API_KEY=xxxxxxxx
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/...
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
#
# --- Example 5: Google AI (Gemini) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=google
# GRAPHITI_EMBEDDER_PROVIDER=google
# GOOGLE_API_KEY=AIzaSyxxxxxxxx
#
# --- Example 6: OpenRouter (multi-provider aggregator) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=openrouter
# GRAPHITI_EMBEDDER_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-xxxxxxxx
# OPENROUTER_LLM_MODEL=anthropic/claude-sonnet-4
# OPENROUTER_EMBEDDING_MODEL=openai/text-embedding-3-small
